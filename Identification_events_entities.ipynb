{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><b>Identification of important events and there words from the document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Import requried libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from mlxtend.frequent_patterns import apriori,association_rules\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import spacy\n",
    "import preprocessor as p\n",
    "from scipy.stats import entropy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Load twitter dataset from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets_corona_May_Tweets.csv',engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[['created_at','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify Unique hashtags\n",
    "utags = []\n",
    "def getTags(x):\n",
    "    tag = \" \".join([str(i)  for i in x.split() if i.startswith(\"#\") ])\n",
    "    for i in x.split():\n",
    "        if i.startswith(\"#\"):\n",
    "            if i not in utags:\n",
    "                utags.append(i)\n",
    "    return(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hashTag'] = df['text'].apply(lambda x:getTags(x))\n",
    "df['date'] = pd.to_datetime(df['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_tweets = len(df)\n",
    "no_tags = len(utags)\n",
    "staring_dateTime = '2020-05-02 00:59'\n",
    "ending_dateTime = '2020-05-02 00:03'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data =df['text'].apply(lambda x: p.clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text_lc = \"\".join([word.lower() for word in text if word not in string.punctuation]) # remove puntuation\n",
    "    text_rc = re.sub('[0-9]+', '', text_lc)\n",
    "    #after tweepy preprocessing the colon symbol left remain after   \n",
    "    tweet = re.sub(r':', '', text_rc)\n",
    "    tweet = re.sub(r'‚Ä¶', '', tweet)\n",
    "    #replace consecutive non-ASCII characters with a space\n",
    "    tweet = re.sub(r'[^\\x00-\\x7F]+',' ', tweet)\n",
    "    #filter using NLTK library append it to a string\n",
    "    tokens = re.split('\\W+', tweet)    # tokenization\n",
    "    text = [ps.stem(word) for word in tokens ]#if word not in stopword]  # remove stopwords and stemming\n",
    "    return text\n",
    "\n",
    "def clean_textWithoutSteam(text):\n",
    "    text_lc = \"\".join([word.lower() for word in text if word not in string.punctuation]) # remove puntuation\n",
    "    text_rc = re.sub('[0-9]+', '', text_lc)\n",
    "    #after tweepy preprocessing the colon symbol left remain after    \n",
    "    tweet = re.sub(r':', '', text_rc)\n",
    "    tweet = re.sub(r'‚Ä¶', '', tweet)\n",
    "    #replace consecutive non-ASCII characters with a space\n",
    "    tweet = re.sub(r'[^\\x00-\\x7F]+',' ', tweet)\n",
    "    #filter using NLTK library append it to a string\n",
    "    tokens = re.split('\\W+', tweet)    # tokenization\n",
    "    text = [word for word in tokens ]#if word not in stopword]  # remove stopwords\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Create Dataframe of DTM of with stemming and without stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = []\n",
    "ex.append(clean_data[2])\n",
    "ex.append(clean_data[7])\n",
    "ex.append(clean_data[27])\n",
    "example = pd.DataFrame(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countVect(text):\n",
    "    countVectorizer = CountVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\",analyzer=clean_textWithoutSteam,stop_words=None) \n",
    "    countVector = countVectorizer.fit_transform(text)\n",
    "    dtm = pd.DataFrame(countVector.toarray(), columns=countVectorizer.get_feature_names())\n",
    "    \n",
    "    countVectorizer1 = CountVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\",analyzer=clean_text,stop_words=None) \n",
    "    countVector1 = countVectorizer1.fit_transform(text)\n",
    "    dtm1 = pd.DataFrame(countVector1.toarray(), columns=countVectorizer1.get_feature_names())\n",
    "    \n",
    "    return (dtm,dtm1)\n",
    "\n",
    "df_withoutStem, df_withStem = countVect(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example data frame\n",
    "df_exWithoutStem, df_exWithStem = countVect(example[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_wordsTweets = df_withoutStem.sum(axis=1).sum()//3116\n",
    "no_wordsDataset = len(df_withoutStem.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = pd.DataFrame([no_tweets,no_tags,no_wordsTweets,no_wordsDataset,staring_dateTime,ending_dateTime],index=['Number of Tweets',\n",
    "                                                                                                               'Number of Unique Hashtags',\n",
    "                                                                                                               'Average words per tweets',\n",
    "                                                                                                               'Total number of words in dataset',\n",
    "                                                                                                               'Starting dateTime','Ending dateTime'],\n",
    "                   columns=['Dataset Details'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Number of Tweets</th>\n",
       "      <td>3116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of Unique Hashtags</th>\n",
       "      <td>939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average words per tweets</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total number of words in dataset</th>\n",
       "      <td>4729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Starting dateTime</th>\n",
       "      <td>2020-05-02 00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ending dateTime</th>\n",
       "      <td>2020-05-02 00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Dataset Details\n",
       "Number of Tweets                              3116\n",
       "Number of Unique Hashtags                      939\n",
       "Average words per tweets                        10\n",
       "Total number of words in dataset              4729\n",
       "Starting dateTime                 2020-05-02 00:59\n",
       "Ending dateTime                   2020-05-02 00:03"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataset detailed information\n",
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b> Get Association of stemmed tweets and without stemmed tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAssociation(dtm1,dtm):\n",
    "    def encode_units(x):\n",
    "        if x <= 0:\n",
    "            return 0\n",
    "        if x >= 1:\n",
    "            return 1\n",
    "\n",
    "    word_sets_withStem = dtm1.iloc[:,1:].applymap(encode_units)\n",
    "    word_sets_withoutStem = dtm.iloc[:,1:].applymap(encode_units)\n",
    "    \n",
    "    prob_words_withStem = apriori(word_sets_withStem,min_support=0.01,verbose=1,use_colnames=True)\n",
    "    prob_words_withoutStem = apriori(word_sets_withoutStem,min_support=0.01,verbose=1,use_colnames=True)\n",
    "    \n",
    "    rules_withStem = association_rules(prob_words_withStem,min_threshold=0)\n",
    "    rules_withoutStem = association_rules(prob_words_withoutStem,min_threshold=0)\n",
    "    \n",
    "    return(rules_withStem,rules_withoutStem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 48 combinations | Sampling itemset size 12116\n",
      "Processing 48 combinations | Sampling itemset size 12116\n"
     ]
    }
   ],
   "source": [
    "rules_withStem, rules_withoutStem = getAssociation(df_withStem,df_withoutStem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 18 combinations | Sampling itemset size 65\n",
      "Processing 14 combinations | Sampling itemset size 75\n"
     ]
    }
   ],
   "source": [
    "#example data\n",
    "rules_exwithStem, rules_exwithoutStem = getAssociation(df_exWithStem,df_exWithoutStem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example data\n",
    "asso_exwithStem = rules_exwithStem[['antecedents','consequents','support','confidence']]\n",
    "asso_exwithoutStem = rules_exwithoutStem[['antecedents','consequents','support','confidence']]\n",
    "\n",
    "asso_exwithStem.columns = pd.MultiIndex.from_product([['With_Stemming'], asso_exwithStem.columns])\n",
    "asso_exwithoutStem.columns = pd.MultiIndex.from_product([['Without_Stemming'], asso_exwithoutStem.columns])\n",
    "\n",
    "result_ex = pd.concat([asso_exwithStem, asso_exwithoutStem], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rules_withoutStem.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "asso_withStem = rules_withStem[['antecedents','consequents','support','confidence']]\n",
    "asso_withoutStem = rules_withoutStem[['antecedents','consequents','support','confidence']]\n",
    "\n",
    "asso_withStem.columns = pd.MultiIndex.from_product([['With_Stemming'], asso_withStem.columns])\n",
    "asso_withoutStem.columns = pd.MultiIndex.from_product([['Without_Stemming'], asso_withoutStem.columns])\n",
    "\n",
    "result = pd.concat([asso_withStem, asso_withoutStem], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">With_Stemming</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Without_Stemming</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(consid)</td>\n",
       "      <td>(ago)</td>\n",
       "      <td>0.049743</td>\n",
       "      <td>0.981013</td>\n",
       "      <td>(consider)</td>\n",
       "      <td>(ago)</td>\n",
       "      <td>0.049743</td>\n",
       "      <td>0.993590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(ago)</td>\n",
       "      <td>(consid)</td>\n",
       "      <td>0.049743</td>\n",
       "      <td>0.933735</td>\n",
       "      <td>(ago)</td>\n",
       "      <td>(consider)</td>\n",
       "      <td>0.049743</td>\n",
       "      <td>0.933735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(conspiraci)</td>\n",
       "      <td>(ago)</td>\n",
       "      <td>0.049743</td>\n",
       "      <td>0.987261</td>\n",
       "      <td>(conspiracy)</td>\n",
       "      <td>(ago)</td>\n",
       "      <td>0.049743</td>\n",
       "      <td>0.987261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(ago)</td>\n",
       "      <td>(conspiraci)</td>\n",
       "      <td>0.049743</td>\n",
       "      <td>0.933735</td>\n",
       "      <td>(ago)</td>\n",
       "      <td>(conspiracy)</td>\n",
       "      <td>0.049743</td>\n",
       "      <td>0.933735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(fact)</td>\n",
       "      <td>(ago)</td>\n",
       "      <td>0.049743</td>\n",
       "      <td>0.928144</td>\n",
       "      <td>(facts)</td>\n",
       "      <td>(ago)</td>\n",
       "      <td>0.049743</td>\n",
       "      <td>0.981013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  With_Stemming                                    Without_Stemming  \\\n",
       "    antecedents   consequents   support confidence      antecedents   \n",
       "0      (consid)         (ago)  0.049743   0.981013       (consider)   \n",
       "1         (ago)      (consid)  0.049743   0.933735            (ago)   \n",
       "2  (conspiraci)         (ago)  0.049743   0.987261     (conspiracy)   \n",
       "3         (ago)  (conspiraci)  0.049743   0.933735            (ago)   \n",
       "4        (fact)         (ago)  0.049743   0.928144          (facts)   \n",
       "\n",
       "                                      \n",
       "    consequents   support confidence  \n",
       "0         (ago)  0.049743   0.993590  \n",
       "1    (consider)  0.049743   0.933735  \n",
       "2         (ago)  0.049743   0.987261  \n",
       "3  (conspiracy)  0.049743   0.933735  \n",
       "4         (ago)  0.049743   0.981013  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()\n",
    "#support = Probability\n",
    "#confidence = Conditinal Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRanks(x,y):\n",
    "    rank = x.sort_values('confidence',axis = 0, ascending = False, inplace = False)[['antecedents','consequents','confidence']]\n",
    "    rank.reset_index(drop=True,inplace=True)\n",
    "    rank['rank'] = rank.index.values\n",
    "    col = rank.columns.tolist()\n",
    "    col = col[-1:] + col[:-1]\n",
    "    \n",
    "    rank1 = y.sort_values('confidence',axis = 0, ascending = False, inplace = False)[['antecedents','consequents','confidence']]\n",
    "    rank1.reset_index(drop=True,inplace=True)\n",
    "    rank1['rank'] = rank1.index.values\n",
    "    \n",
    "    return(rank[col],rank1[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_asso_withStem, rank_asso_withoutStem = getRanks(rules_withStem, rules_withoutStem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#examle data\n",
    "rank_asso_exwithStem, rank_asso_exwithoutStem = getRanks(rules_exwithStem, rules_exwithoutStem)\n",
    "rank_asso_exwithStem.columns = pd.MultiIndex.from_product([['With_Stemming'], rank_asso_exwithStem.columns])\n",
    "rank_asso_exwithoutStem.columns = pd.MultiIndex.from_product([['Without_Stemming'], rank_asso_exwithoutStem.columns])\n",
    "\n",
    "rank_asso_exresult = pd.concat([rank_asso_exwithStem, rank_asso_exwithoutStem], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">With_Stemming</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Without_Stemming</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>confidence</th>\n",
       "      <th>rank</th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>(bioweapon)</td>\n",
       "      <td>(govern)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>(governments)</td>\n",
       "      <td>(bioweapons)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>(govern)</td>\n",
       "      <td>(bioweapon)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>(topsecret, governments, us, bioweapons)</td>\n",
       "      <td>(inside)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>(relat, report, toll)</td>\n",
       "      <td>(new)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>(topsecret, governments, us)</td>\n",
       "      <td>(inside, bioweapons)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>(report, new, toll)</td>\n",
       "      <td>(relat)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>(governments, us, bioweapons)</td>\n",
       "      <td>(topsecret, inside)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>(relat, new)</td>\n",
       "      <td>(report, toll)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>(topsecret, governments, bioweapons)</td>\n",
       "      <td>(us, inside)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  With_Stemming                                                    \\\n",
       "           rank            antecedents     consequents confidence   \n",
       "0           0.0            (bioweapon)        (govern)        1.0   \n",
       "1           1.0               (govern)     (bioweapon)        1.0   \n",
       "2           2.0  (relat, report, toll)           (new)        1.0   \n",
       "3           3.0    (report, new, toll)         (relat)        1.0   \n",
       "4           4.0           (relat, new)  (report, toll)        1.0   \n",
       "\n",
       "  Without_Stemming                                            \\\n",
       "              rank                               antecedents   \n",
       "0                0                             (governments)   \n",
       "1                1  (topsecret, governments, us, bioweapons)   \n",
       "2                2              (topsecret, governments, us)   \n",
       "3                3             (governments, us, bioweapons)   \n",
       "4                4      (topsecret, governments, bioweapons)   \n",
       "\n",
       "                                    \n",
       "            consequents confidence  \n",
       "0          (bioweapons)        1.0  \n",
       "1              (inside)        1.0  \n",
       "2  (inside, bioweapons)        1.0  \n",
       "3   (topsecret, inside)        1.0  \n",
       "4          (us, inside)        1.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example df\n",
    "rank_asso_exresult.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_asso_withStem.columns = pd.MultiIndex.from_product([['With_Stemming'], rank_asso_withStem.columns])\n",
    "rank_asso_withoutStem.columns = pd.MultiIndex.from_product([['Without_Stemming'], rank_asso_withoutStem.columns])\n",
    "\n",
    "rank_asso_result = pd.concat([rank_asso_withStem, rank_asso_withoutStem], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">With_Stemming</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Without_Stemming</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>confidence</th>\n",
       "      <th>rank</th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(tho, doctor)</td>\n",
       "      <td>(help, nursesnow, shut, claim, front)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(spread, inventor, nineyearold, wash, way, hands)</td>\n",
       "      <td>(come)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(te, never, ago)</td>\n",
       "      <td>(month, thing, theori, fact, verifi)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(theories, consider)</td>\n",
       "      <td>(verified, month, tes, facts, conspiracy, neve...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>(theori, month, ago)</td>\n",
       "      <td>(te, thing, fact, never, verifi)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>(verified, never, theories, conspiracy, things...</td>\n",
       "      <td>(facts)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>(verifi, theori, month)</td>\n",
       "      <td>(te, thing, fact, never, ago)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>(verified, facts, theories, conspiracy, things...</td>\n",
       "      <td>(never)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>(never, theori, month)</td>\n",
       "      <td>(te, thing, fact, verifi, ago)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>(verified, facts, never, conspiracy, things, p...</td>\n",
       "      <td>(theories)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  With_Stemming                           \\\n",
       "           rank              antecedents   \n",
       "0             0            (tho, doctor)   \n",
       "1             1         (te, never, ago)   \n",
       "2             2     (theori, month, ago)   \n",
       "3             3  (verifi, theori, month)   \n",
       "4             4   (never, theori, month)   \n",
       "\n",
       "                                                    Without_Stemming  \\\n",
       "                             consequents confidence             rank   \n",
       "0  (help, nursesnow, shut, claim, front)        1.0              0.0   \n",
       "1   (month, thing, theori, fact, verifi)        1.0              1.0   \n",
       "2       (te, thing, fact, never, verifi)        1.0              2.0   \n",
       "3          (te, thing, fact, never, ago)        1.0              3.0   \n",
       "4         (te, thing, fact, verifi, ago)        1.0              4.0   \n",
       "\n",
       "                                                      \\\n",
       "                                         antecedents   \n",
       "0  (spread, inventor, nineyearold, wash, way, hands)   \n",
       "1                               (theories, consider)   \n",
       "2  (verified, never, theories, conspiracy, things...   \n",
       "3  (verified, facts, theories, conspiracy, things...   \n",
       "4  (verified, facts, never, conspiracy, things, p...   \n",
       "\n",
       "                                                                 \n",
       "                                         consequents confidence  \n",
       "0                                             (come)        1.0  \n",
       "1  (verified, month, tes, facts, conspiracy, neve...        1.0  \n",
       "2                                            (facts)        1.0  \n",
       "3                                            (never)        1.0  \n",
       "4                                         (theories)        1.0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_asso_result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Entropy of all words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log2\n",
    "def shannon(freq,total):\n",
    "    \n",
    "    return(-freq / total * log2(freq / total))\n",
    "\n",
    "def getWordRank(x,y):\n",
    "    no_words = x.iloc[:,1:].sum(axis=0)\n",
    "    tot_words = x.iloc[:,1:].sum().sum()\n",
    "    word_rank = pd.DataFrame(no_words.apply(lambda p: p/tot_words))\n",
    "    word_rank['words'] = word_rank.index\n",
    "    word_rank['count'] = x.iloc[:,1:].sum(axis=0).values\n",
    "    \n",
    "    entr_words = no_words.apply(lambda x: shannon(x,no_words.sum()))\n",
    "    word_rank['entropy'] = entr_words.values\n",
    "    \n",
    "    word_rank.sort_values(0,axis = 0, ascending = False, inplace = True)\n",
    "    word_rank.reset_index(drop=True,inplace=True)\n",
    "    word_rank.rename({0:'probability'},axis=1,inplace=True)\n",
    "    word_rank['rank'] = word_rank.index.values\n",
    "    \n",
    "    \n",
    "    no_words = y.iloc[:,1:].sum(axis=0)\n",
    "    tot_words = y.iloc[:,1:].sum().sum()\n",
    "    word_rank1 = pd.DataFrame(no_words.apply(lambda p: p/tot_words))\n",
    "    word_rank1['words'] = word_rank1.index\n",
    "    word_rank1['count'] = y.iloc[:,1:].sum(axis=0).values\n",
    "    \n",
    "    entr_words = no_words.apply(lambda x: shannon(x,no_words.sum()))\n",
    "    word_rank1['entropy'] = entr_words.values\n",
    "    \n",
    "    word_rank1.sort_values(0,axis = 0, ascending = False, inplace = True)\n",
    "    word_rank1.reset_index(drop=True,inplace=True)\n",
    "    word_rank1.rename({0:'probability'},axis=1,inplace=True)\n",
    "    word_rank1['rank'] = word_rank1.index.values\n",
    "    \n",
    "    \n",
    "    col = ['rank','words','count','probability','entropy']\n",
    "    \n",
    "    return(word_rank[col],word_rank1[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordRank_withStem, wordRank_withoutStem = getWordRank(df_withStem,df_withoutStem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">With_Stemming</th>\n",
       "      <th colspan=\"5\" halign=\"left\">Without_Stemming</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>words</th>\n",
       "      <th>count</th>\n",
       "      <th>probability</th>\n",
       "      <th>entropy</th>\n",
       "      <th>rank</th>\n",
       "      <th>words</th>\n",
       "      <th>count</th>\n",
       "      <th>probability</th>\n",
       "      <th>entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>death</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0</td>\n",
       "      <td>bioweapons</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>bioweapon</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.250</td>\n",
       "      <td>1</td>\n",
       "      <td>death</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>destroy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.250</td>\n",
       "      <td>2</td>\n",
       "      <td>deaths</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>economi</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.250</td>\n",
       "      <td>3</td>\n",
       "      <td>destroy</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>govern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.250</td>\n",
       "      <td>4</td>\n",
       "      <td>economy</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  With_Stemming                                      Without_Stemming  \\\n",
       "           rank      words count probability entropy             rank   \n",
       "0           0.0      death   2.0      0.1250   0.375                0   \n",
       "1           1.0  bioweapon   1.0      0.0625   0.250                1   \n",
       "2           2.0    destroy   1.0      0.0625   0.250                2   \n",
       "3           3.0    economi   1.0      0.0625   0.250                3   \n",
       "4           4.0     govern   1.0      0.0625   0.250                4   \n",
       "\n",
       "                                         \n",
       "        words count probability entropy  \n",
       "0  bioweapons     1      0.0625    0.25  \n",
       "1       death     1      0.0625    0.25  \n",
       "2      deaths     1      0.0625    0.25  \n",
       "3     destroy     1      0.0625    0.25  \n",
       "4     economy     1      0.0625    0.25  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example data\n",
    "wordRank_exwithStem, wordRank_exwithoutStem = getWordRank(df_exWithStem,df_exWithoutStem)\n",
    "\n",
    "wordRank_exwithStem.columns = pd.MultiIndex.from_product([['With_Stemming'], wordRank_exwithStem.columns])\n",
    "wordRank_exwithoutStem.columns = pd.MultiIndex.from_product([['Without_Stemming'], wordRank_exwithoutStem.columns])\n",
    "\n",
    "wordRank_exresult = pd.concat([wordRank_exwithStem, wordRank_exwithoutStem], axis = 1)\n",
    "wordRank_exresult.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#origle dataset\n",
    "wordRank_withStem.columns = pd.MultiIndex.from_product([['With_Stemming'], wordRank_withStem.columns])\n",
    "wordRank_withoutStem.columns = pd.MultiIndex.from_product([['Without_Stemming'], wordRank_withoutStem.columns])\n",
    "\n",
    "wordRank_result = pd.concat([wordRank_withStem, wordRank_withoutStem], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">With_Stemming</th>\n",
       "      <th colspan=\"5\" halign=\"left\">Without_Stemming</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>words</th>\n",
       "      <th>count</th>\n",
       "      <th>probability</th>\n",
       "      <th>entropy</th>\n",
       "      <th>rank</th>\n",
       "      <th>words</th>\n",
       "      <th>count</th>\n",
       "      <th>probability</th>\n",
       "      <th>entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>nation</td>\n",
       "      <td>616.0</td>\n",
       "      <td>0.020930</td>\n",
       "      <td>0.116755</td>\n",
       "      <td>0</td>\n",
       "      <td>nation</td>\n",
       "      <td>540</td>\n",
       "      <td>0.018348</td>\n",
       "      <td>0.105836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>help</td>\n",
       "      <td>544.0</td>\n",
       "      <td>0.018484</td>\n",
       "      <td>0.106423</td>\n",
       "      <td>1</td>\n",
       "      <td>doctors</td>\n",
       "      <td>525</td>\n",
       "      <td>0.017838</td>\n",
       "      <td>0.103621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>doctor</td>\n",
       "      <td>534.0</td>\n",
       "      <td>0.018144</td>\n",
       "      <td>0.104952</td>\n",
       "      <td>2</td>\n",
       "      <td>line</td>\n",
       "      <td>519</td>\n",
       "      <td>0.017634</td>\n",
       "      <td>0.102729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>claim</td>\n",
       "      <td>526.0</td>\n",
       "      <td>0.017872</td>\n",
       "      <td>0.103769</td>\n",
       "      <td>3</td>\n",
       "      <td>helping</td>\n",
       "      <td>519</td>\n",
       "      <td>0.017634</td>\n",
       "      <td>0.102729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>line</td>\n",
       "      <td>523.0</td>\n",
       "      <td>0.017770</td>\n",
       "      <td>0.103324</td>\n",
       "      <td>4</td>\n",
       "      <td>front</td>\n",
       "      <td>518</td>\n",
       "      <td>0.017600</td>\n",
       "      <td>0.102580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  With_Stemming                                      Without_Stemming  \\\n",
       "           rank   words  count probability   entropy             rank   \n",
       "0           0.0  nation  616.0    0.020930  0.116755                0   \n",
       "1           1.0    help  544.0    0.018484  0.106423                1   \n",
       "2           2.0  doctor  534.0    0.018144  0.104952                2   \n",
       "3           3.0   claim  526.0    0.017872  0.103769                3   \n",
       "4           4.0    line  523.0    0.017770  0.103324                4   \n",
       "\n",
       "                                        \n",
       "     words count probability   entropy  \n",
       "0   nation   540    0.018348  0.105836  \n",
       "1  doctors   525    0.017838  0.103621  \n",
       "2     line   519    0.017634  0.102729  \n",
       "3  helping   519    0.017634  0.102729  \n",
       "4    front   518    0.017600  0.102580  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordRank_result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Identify all Named entity occurred in all tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEntityRank(data):\n",
    "    text = []\n",
    "    label = []\n",
    "    disc = []\n",
    "    def show_ents(doc):\n",
    "    # Write a function to display basic entity info:\n",
    "        if doc.ents:\n",
    "            for ent in doc.ents:\n",
    "                text.append(ent.text)\n",
    "                label.append(ent.label_)\n",
    "                disc.append(str(spacy.explain(ent.label_)))\n",
    "        return([text,label,disc])\n",
    "    ner = data.apply(lambda x: show_ents(nlp(x)))\n",
    "    df_ner = pd.DataFrame([text,label,disc]).transpose()\n",
    "    df_ner.columns = ['text','ent','discription']\n",
    "\n",
    "    ner_des = pd.DataFrame(df_ner['ent'].value_counts())\n",
    "    ner_des['entity'] = ner_des.index\n",
    "    ner_des.reset_index(drop=True,inplace=True)\n",
    "    ner_des['discription'] = pd.DataFrame(df_ner['discription'].value_counts()).index\n",
    "    ner_des.rename({'ent':'count'},axis=1,inplace=True)\n",
    "    ner_des = ner_des[['entity','discription','count']]\n",
    "\n",
    "    ner_des['probability'] = ner_des['count'].apply(lambda x: x/ner_des['count'].sum())\n",
    "    ner_des['rank'] = ner_des.index\n",
    "    \n",
    "    return(ner_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_des = getEntityRank(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>discription</th>\n",
       "      <th>count</th>\n",
       "      <th>probability</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DATE</td>\n",
       "      <td>Absolute or relative dates or periods</td>\n",
       "      <td>737</td>\n",
       "      <td>0.213809</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ORG</td>\n",
       "      <td>Companies, agencies, institutions, etc.</td>\n",
       "      <td>681</td>\n",
       "      <td>0.197563</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GPE</td>\n",
       "      <td>Countries, cities, states</td>\n",
       "      <td>636</td>\n",
       "      <td>0.184508</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PERSON</td>\n",
       "      <td>People, including fictional</td>\n",
       "      <td>615</td>\n",
       "      <td>0.178416</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NORP</td>\n",
       "      <td>Nationalities or religious or political groups</td>\n",
       "      <td>381</td>\n",
       "      <td>0.110531</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>Numerals that do not fall under another type</td>\n",
       "      <td>117</td>\n",
       "      <td>0.033943</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TIME</td>\n",
       "      <td>Times smaller than a day</td>\n",
       "      <td>53</td>\n",
       "      <td>0.015376</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MONEY</td>\n",
       "      <td>Monetary values, including unit</td>\n",
       "      <td>43</td>\n",
       "      <td>0.012475</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ORDINAL</td>\n",
       "      <td>\"first\", \"second\", etc.</td>\n",
       "      <td>38</td>\n",
       "      <td>0.011024</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>Non-GPE locations, mountain ranges, bodies of ...</td>\n",
       "      <td>33</td>\n",
       "      <td>0.009574</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LOC</td>\n",
       "      <td>Objects, vehicles, foods, etc. (not services)</td>\n",
       "      <td>33</td>\n",
       "      <td>0.009574</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FAC</td>\n",
       "      <td>Buildings, airports, highways, bridges, etc.</td>\n",
       "      <td>30</td>\n",
       "      <td>0.008703</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>WORK_OF_ART</td>\n",
       "      <td>Titles of books, songs, etc.</td>\n",
       "      <td>28</td>\n",
       "      <td>0.008123</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>QUANTITY</td>\n",
       "      <td>Measurements, as of weight or distance</td>\n",
       "      <td>6</td>\n",
       "      <td>0.001741</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PERCENT</td>\n",
       "      <td>Named documents made into laws.</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001451</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LAW</td>\n",
       "      <td>Percentage, including \"%\"</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001451</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LANGUAGE</td>\n",
       "      <td>Named hurricanes, battles, wars, sports events...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>EVENT</td>\n",
       "      <td>Any named language</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         entity                                        discription  count  \\\n",
       "0          DATE              Absolute or relative dates or periods    737   \n",
       "1           ORG            Companies, agencies, institutions, etc.    681   \n",
       "2           GPE                          Countries, cities, states    636   \n",
       "3        PERSON                        People, including fictional    615   \n",
       "4          NORP     Nationalities or religious or political groups    381   \n",
       "5      CARDINAL       Numerals that do not fall under another type    117   \n",
       "6          TIME                           Times smaller than a day     53   \n",
       "7         MONEY                    Monetary values, including unit     43   \n",
       "8       ORDINAL                            \"first\", \"second\", etc.     38   \n",
       "9       PRODUCT  Non-GPE locations, mountain ranges, bodies of ...     33   \n",
       "10          LOC      Objects, vehicles, foods, etc. (not services)     33   \n",
       "11          FAC       Buildings, airports, highways, bridges, etc.     30   \n",
       "12  WORK_OF_ART                       Titles of books, songs, etc.     28   \n",
       "13     QUANTITY             Measurements, as of weight or distance      6   \n",
       "14      PERCENT                    Named documents made into laws.      5   \n",
       "15          LAW                          Percentage, including \"%\"      5   \n",
       "16     LANGUAGE  Named hurricanes, battles, wars, sports events...      3   \n",
       "17        EVENT                                 Any named language      3   \n",
       "\n",
       "    probability  rank  \n",
       "0      0.213809     0  \n",
       "1      0.197563     1  \n",
       "2      0.184508     2  \n",
       "3      0.178416     3  \n",
       "4      0.110531     4  \n",
       "5      0.033943     5  \n",
       "6      0.015376     6  \n",
       "7      0.012475     7  \n",
       "8      0.011024     8  \n",
       "9      0.009574     9  \n",
       "10     0.009574    10  \n",
       "11     0.008703    11  \n",
       "12     0.008123    12  \n",
       "13     0.001741    13  \n",
       "14     0.001451    14  \n",
       "15     0.001451    15  \n",
       "16     0.000870    16  \n",
       "17     0.000870    17  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_des"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Information gain of all possible pair of words from without stemmed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[wordRank_withoutStem['words'='line']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([519])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt[cnt['words']=='line']['count'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bioweapons</th>\n",
       "      <th>death</th>\n",
       "      <th>deaths</th>\n",
       "      <th>destroy</th>\n",
       "      <th>economy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bioweapons</th>\n",
       "      <td>9.762707</td>\n",
       "      <td>9.762707</td>\n",
       "      <td>9.762707</td>\n",
       "      <td>9.762707</td>\n",
       "      <td>9.762707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>death</th>\n",
       "      <td>9.762707</td>\n",
       "      <td>9.762707</td>\n",
       "      <td>9.762707</td>\n",
       "      <td>9.762707</td>\n",
       "      <td>9.762707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deaths</th>\n",
       "      <td>9.762707</td>\n",
       "      <td>9.762707</td>\n",
       "      <td>9.762707</td>\n",
       "      <td>9.762707</td>\n",
       "      <td>9.762707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>destroy</th>\n",
       "      <td>9.762707</td>\n",
       "      <td>9.762707</td>\n",
       "      <td>9.762707</td>\n",
       "      <td>9.762707</td>\n",
       "      <td>9.762707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>economy</th>\n",
       "      <td>9.762707</td>\n",
       "      <td>9.762707</td>\n",
       "      <td>9.762707</td>\n",
       "      <td>9.762707</td>\n",
       "      <td>9.762707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            bioweapons     death    deaths   destroy   economy\n",
       "bioweapons    9.762707  9.762707  9.762707  9.762707  9.762707\n",
       "death         9.762707  9.762707  9.762707  9.762707  9.762707\n",
       "deaths        9.762707  9.762707  9.762707  9.762707  9.762707\n",
       "destroy       9.762707  9.762707  9.762707  9.762707  9.762707\n",
       "economy       9.762707  9.762707  9.762707  9.762707  9.762707"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = wordRank_withoutStem['Without_Stemming']\n",
    "H_data = cnt['count'].apply(lambda x: shannon(x,cnt['count'].sum())).sum()\n",
    "\n",
    "def infog(H_x,H_y,cnt_x,cnt_y):\n",
    "    I_xy = H_data -(cnt_x/cnt_data * H_x + cnt_y/cnt_data * H_y)\n",
    "    return(I_xy)\n",
    "\n",
    "entr_words =wordRank_exresult['Without_Stemming']\n",
    "\n",
    "fin = []\n",
    "for i in entr_words.iterrows():\n",
    "    #print(i[1]['entropy'])\n",
    "    #print('...')\n",
    "    res = []\n",
    "    for x in entr_words.iterrows():\n",
    "        res.append(infog(i[1]['entropy'],x[1]['entropy'],i[1]['count'],x[1]['count']))\n",
    "    fin.append(res)\n",
    "    \n",
    "pd.DataFrame(fin,columns=entr_words['words'].values,index=entr_words['words'].values).iloc[:5,:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b> Cosine similarity of each documents of with stemming and without stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">With_Stemming</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Without_Stemming</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.125988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  With_Stemming                Without_Stemming               \n",
       "              0    1         2                0    1         2\n",
       "0      1.000000  0.0  0.142857         1.000000  0.0  0.125988\n",
       "1      0.000000  1.0  0.000000         0.000000  1.0  0.000000\n",
       "2      0.142857  0.0  1.000000         0.125988  0.0  1.000000"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example data\n",
    "a=pd.DataFrame(cosine_similarity(df_exWithoutStem, df_exWithoutStem))\n",
    "b=pd.DataFrame(cosine_similarity(df_exWithStem, df_exWithStem))\n",
    "a.columns = pd.MultiIndex.from_product([['With_Stemming'], a.columns])\n",
    "b.columns = pd.MultiIndex.from_product([['Without_Stemming'], b.columns])\n",
    "\n",
    "cosine_exResult = pd.concat([a, b], axis = 1)\n",
    "cosine_exResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3106</th>\n",
       "      <th>3107</th>\n",
       "      <th>3108</th>\n",
       "      <th>3109</th>\n",
       "      <th>3110</th>\n",
       "      <th>3111</th>\n",
       "      <th>3112</th>\n",
       "      <th>3113</th>\n",
       "      <th>3114</th>\n",
       "      <th>3115</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.087039</td>\n",
       "      <td>0.113961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.113961</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.083624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.100504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.150756</td>\n",
       "      <td>0.087039</td>\n",
       "      <td>0.087039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.087039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.123091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.087039</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.109109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109109</td>\n",
       "      <td>0.087039</td>\n",
       "      <td>0.080064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.087039</td>\n",
       "      <td>0.096225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.087039</td>\n",
       "      <td>0.144338</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.087039</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.113961</td>\n",
       "      <td>0.109109</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.113961</td>\n",
       "      <td>0.209657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.113961</td>\n",
       "      <td>0.125988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.113961</td>\n",
       "      <td>0.188982</td>\n",
       "      <td>0.109109</td>\n",
       "      <td>0.109109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.113961</td>\n",
       "      <td>0.218218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.154303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.113961</td>\n",
       "      <td>0.109109</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.113961</td>\n",
       "      <td>0.104828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.113961</td>\n",
       "      <td>0.125988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.113961</td>\n",
       "      <td>0.188982</td>\n",
       "      <td>0.109109</td>\n",
       "      <td>0.109109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.113961</td>\n",
       "      <td>0.218218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.154303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2     3         4         5         6     7     \\\n",
       "0  1.000000  0.087039  0.113961   0.0  0.113961  0.090909  0.083624   0.0   \n",
       "1  0.087039  1.000000  0.109109   0.0  0.109109  0.087039  0.080064   0.0   \n",
       "2  0.113961  0.109109  1.000000   0.0  0.285714  0.113961  0.209657   0.0   \n",
       "3  0.000000  0.000000  0.000000   1.0  0.000000  0.000000  0.000000   0.0   \n",
       "4  0.113961  0.109109  0.285714   0.0  1.000000  0.113961  0.104828   0.0   \n",
       "\n",
       "       8         9     ...  3106      3107      3108      3109      3110  \\\n",
       "0  0.090909  0.100504  ...   0.0  1.000000  0.150756  0.087039  0.087039   \n",
       "1  0.087039  0.096225  ...   0.0  0.087039  0.144338  0.083333  0.083333   \n",
       "2  0.113961  0.125988  ...   0.0  0.113961  0.188982  0.109109  0.109109   \n",
       "3  0.000000  0.000000  ...   0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.113961  0.125988  ...   0.0  0.113961  0.188982  0.109109  0.109109   \n",
       "\n",
       "   3111      3112      3113  3114      3115  \n",
       "0   0.0  0.090909  0.087039   0.0  0.123091  \n",
       "1   0.0  0.087039  0.083333   0.0  0.117851  \n",
       "2   0.0  0.113961  0.218218   0.0  0.154303  \n",
       "3   0.0  0.000000  0.000000   0.0  0.000000  \n",
       "4   0.0  0.113961  0.218218   0.0  0.154303  \n",
       "\n",
       "[5 rows x 3116 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_similarity_withStem = pd.DataFrame(cosine_similarity(df_withStem, df_withStem))\n",
    "docs_similarity_withStem.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3106</th>\n",
       "      <th>3107</th>\n",
       "      <th>3108</th>\n",
       "      <th>3109</th>\n",
       "      <th>3110</th>\n",
       "      <th>3111</th>\n",
       "      <th>3112</th>\n",
       "      <th>3113</th>\n",
       "      <th>3114</th>\n",
       "      <th>3115</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.087039</td>\n",
       "      <td>0.113961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.113961</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.083624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.100504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.150756</td>\n",
       "      <td>0.087039</td>\n",
       "      <td>0.087039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.087039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.123091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.087039</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.109109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109109</td>\n",
       "      <td>0.087039</td>\n",
       "      <td>0.080064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.087039</td>\n",
       "      <td>0.096225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.087039</td>\n",
       "      <td>0.144338</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.087039</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.113961</td>\n",
       "      <td>0.109109</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.113961</td>\n",
       "      <td>0.104828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.113961</td>\n",
       "      <td>0.125988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.113961</td>\n",
       "      <td>0.188982</td>\n",
       "      <td>0.109109</td>\n",
       "      <td>0.109109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.113961</td>\n",
       "      <td>0.218218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.154303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.113961</td>\n",
       "      <td>0.109109</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.113961</td>\n",
       "      <td>0.104828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.113961</td>\n",
       "      <td>0.125988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.113961</td>\n",
       "      <td>0.188982</td>\n",
       "      <td>0.109109</td>\n",
       "      <td>0.109109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.113961</td>\n",
       "      <td>0.218218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.154303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2     3         4         5         6     7     \\\n",
       "0  1.000000  0.087039  0.113961   0.0  0.113961  0.090909  0.083624   0.0   \n",
       "1  0.087039  1.000000  0.109109   0.0  0.109109  0.087039  0.080064   0.0   \n",
       "2  0.113961  0.109109  1.000000   0.0  0.285714  0.113961  0.104828   0.0   \n",
       "3  0.000000  0.000000  0.000000   1.0  0.000000  0.000000  0.000000   0.0   \n",
       "4  0.113961  0.109109  0.285714   0.0  1.000000  0.113961  0.104828   0.0   \n",
       "\n",
       "       8         9     ...  3106      3107      3108      3109      3110  \\\n",
       "0  0.090909  0.100504  ...   0.0  1.000000  0.150756  0.087039  0.087039   \n",
       "1  0.087039  0.096225  ...   0.0  0.087039  0.144338  0.083333  0.083333   \n",
       "2  0.113961  0.125988  ...   0.0  0.113961  0.188982  0.109109  0.109109   \n",
       "3  0.000000  0.000000  ...   0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.113961  0.125988  ...   0.0  0.113961  0.188982  0.109109  0.109109   \n",
       "\n",
       "   3111      3112      3113  3114      3115  \n",
       "0   0.0  0.090909  0.087039   0.0  0.123091  \n",
       "1   0.0  0.087039  0.083333   0.0  0.117851  \n",
       "2   0.0  0.113961  0.218218   0.0  0.154303  \n",
       "3   0.0  0.000000  0.000000   0.0  0.000000  \n",
       "4   0.0  0.113961  0.218218   0.0  0.154303  \n",
       "\n",
       "[5 rows x 3116 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_similarity_withoutStem = pd.DataFrame(cosine_similarity(df_withoutStem, df_withoutStem))\n",
    "docs_similarity_withoutStem.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Top words from all events using Uncertinity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.051463\n",
       "1      0.008643\n",
       "2      0.000786\n",
       "3      0.152033\n",
       "4      0.044196\n",
       "         ...   \n",
       "934    0.000196\n",
       "935    0.000196\n",
       "936    0.000196\n",
       "937    0.000196\n",
       "938    0.000196\n",
       "Name: count, Length: 939, dtype: float64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#probability of hashtags/event\n",
    "cnt_tags = []\n",
    "for i in utags:\n",
    "    cnt_tags.append(len(df[df['text'].apply(lambda x: i in x)]))\n",
    "\n",
    "df_tags = pd.DataFrame([utags,cnt_tags],index=['tags','count']).transpose()\n",
    "\n",
    "total_tags  = sum(cnt_tags) #len(utags)\n",
    "p_allTags = df_tags['probability'] = df_tags['count'].apply(lambda x: x/total_tags)\n",
    "p_allTags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "abandon              0.000212\n",
       "abbey                0.000212\n",
       "abdiaziz             0.000212\n",
       "abilene              0.000212\n",
       "able                 0.000423\n",
       "                       ...   \n",
       "zoey                 0.000212\n",
       "zombieapocalyptic    0.000212\n",
       "zombies              0.000212\n",
       "zone                 0.002538\n",
       "zoom                 0.000423\n",
       "Length: 4728, dtype: float64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#probability of words\n",
    "total_w = len(df_withoutStem.iloc[:,1:].columns)\n",
    "p_AllWords = df_withoutStem.iloc[:,1:].sum().apply(lambda x: x/total_w)\n",
    "p_AllWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#addition P(tags) + P(words)\n",
    "p_add=[]\n",
    "for i in p_allTags:\n",
    "    p_add.append(p_AllWords.apply(lambda x: x+i))\n",
    "    \n",
    "prob_add = pd.DataFrame(p_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intersection  P(tags I word) = n(words from specific hashtag) / n(total words from all hashtags)\n",
    "\n",
    "total_wsI = df_withoutStem.iloc[:,1:].sum().sum()\n",
    "p_TagIword = []\n",
    "for i in utags:\n",
    "    df_tagWord = df[df['text'].apply(lambda x: i in x)]\n",
    "    df_tagWord.reset_index(inplace=True)\n",
    "    clean_data_tags =df_tagWord['text'].apply(lambda x: p.clean(x))\n",
    "    df_wsI,df_sI = countVect(clean_data_tags)\n",
    "   # print(total_wsI)\n",
    "    p_TagIword.append(df_wsI.iloc[:,1:].sum().apply(lambda x: x/total_wsI))\n",
    "    \n",
    "\n",
    "prob_TagIword = pd.DataFrame(p_TagIword)\n",
    "prob_TagIword.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#union \n",
    "comman_colms = np.intersect1d(prob_add.columns,prob_TagIword.columns)\n",
    "prob_union = prob_add[comman_colms] - prob_TagIword[comman_colms]\n",
    "\n",
    "col_add = []\n",
    "col_Intr=[]\n",
    "for i in prob_add.columns:\n",
    "    if i not in comman_colms:\n",
    "        col_add.append(i)\n",
    "           \n",
    "for j in prob_TagIword.columns:    \n",
    "    if j not in comman_colms:\n",
    "        col_Intr.append(j)\n",
    "        \n",
    "uni_prob = prob_union.join(prob_add[col_add]).join(prob_TagIword[col_Intr])\n",
    "uni_prob = uni_prob[uni_prob.columns.sort_values().values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>about</th>\n",
       "      <th>action</th>\n",
       "      <th>additional</th>\n",
       "      <th>administration</th>\n",
       "      <th>advises</th>\n",
       "      <th>against</th>\n",
       "      <th>aid</th>\n",
       "      <th>amp</th>\n",
       "      <th>an</th>\n",
       "      <th>and</th>\n",
       "      <th>...</th>\n",
       "      <th>sanitizer</th>\n",
       "      <th>images</th>\n",
       "      <th>mapping</th>\n",
       "      <th>momo</th>\n",
       "      <th>omochi</th>\n",
       "      <th>preview</th>\n",
       "      <th>projection</th>\n",
       "      <th>keeps</th>\n",
       "      <th>restarting</th>\n",
       "      <th>tractors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>#…</th>\n",
       "      <td>0.001320</td>\n",
       "      <td>0.00066</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.00066</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.00066</td>\n",
       "      <td>0.001320</td>\n",
       "      <td>0.161097</td>\n",
       "      <td>0.164398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#Covid_19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.003931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.102216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#CoronaVirusUpdate</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.043245</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#coronavirus</th>\n",
       "      <td>0.008493</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>0.00067</td>\n",
       "      <td>0.011174</td>\n",
       "      <td>0.003576</td>\n",
       "      <td>0.032853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#COVID</th>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.036903</td>\n",
       "      <td>0.003844</td>\n",
       "      <td>0.019989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#cities</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.172981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#inequalities…</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.172981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#MayDayStrike…</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#Bengal</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#WhereAreTheTests</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>939 rows × 3587 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       about   action  additional  administration  advises  \\\n",
       "#…                  0.001320  0.00066    0.000660        0.000660  0.00066   \n",
       "#Covid_19           0.000000  0.00000    0.000000        0.000000  0.00000   \n",
       "#CoronaVirusUpdate  0.000000  0.00000    0.000000        0.000000  0.00000   \n",
       "#coronavirus        0.008493  0.00000    0.000447        0.000223  0.00000   \n",
       "#COVID              0.006150  0.00000    0.000000        0.000000  0.00000   \n",
       "...                      ...      ...         ...             ...      ...   \n",
       "#cities             0.000000  0.00000    0.000000        0.000000  0.00000   \n",
       "#inequalities…      0.000000  0.00000    0.000000        0.000000  0.00000   \n",
       "#MayDayStrike…      0.000000  0.00000    0.000000        0.000000  0.00000   \n",
       "#Bengal             0.000000  0.00000    0.000000        0.000000  0.00000   \n",
       "#WhereAreTheTests   0.000000  0.00000    0.000000        0.000000  0.00000   \n",
       "\n",
       "                     against      aid       amp        an       and  ...  \\\n",
       "#…                  0.000660  0.00066  0.001320  0.161097  0.164398  ...   \n",
       "#Covid_19           0.000000  0.00000  0.003931  0.000000  0.102216  ...   \n",
       "#CoronaVirusUpdate  0.000000  0.00000  0.043245  0.000000  0.043245  ...   \n",
       "#coronavirus        0.002011  0.00067  0.011174  0.003576  0.032853  ...   \n",
       "#COVID              0.001538  0.00000  0.036903  0.003844  0.019989  ...   \n",
       "...                      ...      ...       ...       ...       ...  ...   \n",
       "#cities             0.000000  0.00000  0.000000  0.000000  0.172981  ...   \n",
       "#inequalities…      0.000000  0.00000  0.000000  0.000000  0.172981  ...   \n",
       "#MayDayStrike…      0.000000  0.00000  0.000000  0.000000  0.000000  ...   \n",
       "#Bengal             0.000000  0.00000  0.000000  0.000000  0.000000  ...   \n",
       "#WhereAreTheTests   0.000000  0.00000  0.000000  0.000000  0.000000  ...   \n",
       "\n",
       "                    sanitizer  images  mapping  momo  omochi  preview  \\\n",
       "#…                        0.0     0.0      0.0   0.0     0.0      0.0   \n",
       "#Covid_19                 0.0     0.0      0.0   0.0     0.0      0.0   \n",
       "#CoronaVirusUpdate        0.0     0.0      0.0   0.0     0.0      0.0   \n",
       "#coronavirus              0.0     0.0      0.0   0.0     0.0      0.0   \n",
       "#COVID                    0.0     0.0      0.0   0.0     0.0      0.0   \n",
       "...                       ...     ...      ...   ...     ...      ...   \n",
       "#cities                   0.0     0.0      0.0   0.0     0.0      0.0   \n",
       "#inequalities…            0.0     0.0      0.0   0.0     0.0      0.0   \n",
       "#MayDayStrike…            0.0     0.0      0.0   0.0     0.0      0.0   \n",
       "#Bengal                   0.0     0.0      0.0   0.0     0.0      0.0   \n",
       "#WhereAreTheTests         0.0     0.0      0.0   0.0     0.0      0.0   \n",
       "\n",
       "                    projection  keeps  restarting  tractors  \n",
       "#…                         0.0    0.0         0.0       0.0  \n",
       "#Covid_19                  0.0    0.0         0.0       0.0  \n",
       "#CoronaVirusUpdate         0.0    0.0         0.0       0.0  \n",
       "#coronavirus               0.0    0.0         0.0       0.0  \n",
       "#COVID                     0.0    0.0         0.0       0.0  \n",
       "...                        ...    ...         ...       ...  \n",
       "#cities                    0.0    0.0         0.0       0.0  \n",
       "#inequalities…             0.0    0.0         0.0       0.0  \n",
       "#MayDayStrike…             0.0    0.0         0.0       0.0  \n",
       "#Bengal                    0.0    0.0         0.0       0.0  \n",
       "#WhereAreTheTests          0.0    0.0         0.0       0.0  \n",
       "\n",
       "[939 rows x 3587 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Uncertinity/ conditinal probability\n",
    "#P(word/tags) = P( tags intersection word) / P(tags)\n",
    "\n",
    "prob_uncertinity = prob_TagIword.div(p_allTags,axis=0)\n",
    "\n",
    "prob_uncertinity.index = utags\n",
    "prob_uncertinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#ldnont</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>poised</th>\n",
       "      <td>0.172981</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>0.172981</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>0.172981</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>big</th>\n",
       "      <td>0.172981</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>column</th>\n",
       "      <td>0.172981</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         #ldnont  Rank\n",
       "poised  0.172981     0\n",
       "for     0.172981     1\n",
       "a       0.172981     2\n",
       "big     0.172981     3\n",
       "column  0.172981     4"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#words ranking of single hashtags\n",
    "sample = pd.DataFrame(prob_uncertinity.iloc[40,:].sort_values(ascending=False)).head(50)\n",
    "r = []\n",
    "for i in range(len(sample)):\n",
    "    r.append(i)\n",
    "\n",
    "sample['Rank'] = r\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top ten hashtags\n",
    "top_tags = df_tags.sort_values(by='probability',ascending=False)['tags'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top ten words of each hashtags\n",
    "label=[]\n",
    "coln=[]\n",
    "val=[]\n",
    "for i in range(len(prob_uncertinity)):\n",
    "\n",
    "    s = pd.DataFrame(prob_uncertinity.iloc[i,:].sort_values(ascending=False).head(10))\n",
    "    label.append(s.index)\n",
    "    coln.append(s.columns)\n",
    "    val.append(s)\n",
    "\n",
    "top_wordsWithHash = pd.DataFrame(label,index=pd.DataFrame(coln).values).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(#corona,)</th>\n",
       "      <th>(#coronavirus,)</th>\n",
       "      <th>(#Corona,)</th>\n",
       "      <th>(#Coronavirus,)</th>\n",
       "      <th>(#…,)</th>\n",
       "      <th>(#COVID,)</th>\n",
       "      <th>(#COVID19,)</th>\n",
       "      <th>(#CoronaVirus,)</th>\n",
       "      <th>(#Covid_19,)</th>\n",
       "      <th>(#covid,)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>to</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>the</td>\n",
       "      <td>a</td>\n",
       "      <td>and</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>in</td>\n",
       "      <td>and</td>\n",
       "      <td>has</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>and</td>\n",
       "      <td>in</td>\n",
       "      <td>and</td>\n",
       "      <td>in</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>deaths</td>\n",
       "      <td>you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "      <td>and</td>\n",
       "      <td>this</td>\n",
       "      <td>amp</td>\n",
       "      <td>amp</td>\n",
       "      <td>is</td>\n",
       "      <td>from</td>\n",
       "      <td>are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>on</td>\n",
       "      <td>on</td>\n",
       "      <td>has</td>\n",
       "      <td>is</td>\n",
       "      <td>that</td>\n",
       "      <td>for</td>\n",
       "      <td>were</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>from</td>\n",
       "      <td>from</td>\n",
       "      <td>a</td>\n",
       "      <td>has</td>\n",
       "      <td>reduce</td>\n",
       "      <td>this</td>\n",
       "      <td>deaths</td>\n",
       "      <td>to</td>\n",
       "      <td>revised</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>is</td>\n",
       "      <td>is</td>\n",
       "      <td>is</td>\n",
       "      <td>people</td>\n",
       "      <td>up</td>\n",
       "      <td>that</td>\n",
       "      <td>cases</td>\n",
       "      <td>true</td>\n",
       "      <td>actually</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>for</td>\n",
       "      <td>for</td>\n",
       "      <td>for</td>\n",
       "      <td>with</td>\n",
       "      <td>with</td>\n",
       "      <td>deaths</td>\n",
       "      <td>this</td>\n",
       "      <td>in</td>\n",
       "      <td>cdc</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>on</td>\n",
       "      <td>on</td>\n",
       "      <td>has</td>\n",
       "      <td>remdesivir</td>\n",
       "      <td>spread</td>\n",
       "      <td>from</td>\n",
       "      <td>may</td>\n",
       "      <td>deaths</td>\n",
       "      <td>k</td>\n",
       "      <td>this</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  (#corona,) (#coronavirus,) (#Corona,) (#Coronavirus,)   (#…,) (#COVID,)  \\\n",
       "0        the             the        the             the     the       the   \n",
       "1         to              to         to              to      to        to   \n",
       "2         of              of         of              of      of        of   \n",
       "3          a               a        and              in     and        in   \n",
       "4         in              in         in             and    this       amp   \n",
       "5        and             and         on              on     has        is   \n",
       "6       from            from          a             has  reduce      this   \n",
       "7         is              is         is          people      up      that   \n",
       "8        for             for        for            with    with    deaths   \n",
       "9         on              on        has      remdesivir  spread      from   \n",
       "\n",
       "  (#COVID19,) (#CoronaVirus,) (#Covid_19,) (#covid,)  \n",
       "0          to             the          the        to  \n",
       "1         the               a          and         a  \n",
       "2          in             and          has       the  \n",
       "3          of              of       deaths       you  \n",
       "4         amp              is         from       are  \n",
       "5        that             for         were        of  \n",
       "6      deaths              to      revised       for  \n",
       "7       cases            true     actually       and  \n",
       "8        this              in          cdc        is  \n",
       "9         may          deaths            k      this  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_wordsWithHash[[top_tags]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
